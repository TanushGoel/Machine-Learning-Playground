{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MusicAI 1.0 LSTM Nocturnes",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOedxI5OjalVmqenosn37bY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TanushGoel/Machine-Learning-Playground/blob/master/MusicAI_1_0_LSTM_Nocturnes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwFLT7IBzoux",
        "colab_type": "code",
        "outputId": "ac5d6db8-dcf8-4e6b-87c9-5fd0b1aa2ff0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# imports\n",
        "from music21 import converter, instrument, note, chord, stream, common\n",
        "import os\n",
        "import os.path\n",
        "from os import path\n",
        "import zipfile\n",
        "import glob\n",
        "import pickle\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout, Activation, Concatenate\n",
        "from keras.layers.core import*\n",
        "from keras import initializers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JaYrzaqkPs7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# upload zip file first\n",
        "for i in os.listdir():\n",
        "  global zip_file, folder\n",
        "  if zipfile.is_zipfile(i):\n",
        "      zip_file = str(i)\n",
        "      folder = zip_file[:-4]\n",
        "      with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "          zip_ref.extractall(os.mkdir(folder))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mddrGwMu10Em",
        "colab_type": "code",
        "outputId": "bdb20aae-53c3-4b90-80cf-1cf1b18e3978",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# one file at a time\n",
        "notes = []\n",
        "count = 0\n",
        "total = len(os.listdir(folder))\n",
        "\n",
        "for file in glob.glob(folder+\"/*.mid\"):\n",
        "\n",
        "    count+=1\n",
        "    print(f\"{count*100/total:1.2f}% Complete\")\n",
        "\n",
        "    try:  \n",
        "      midi = converter.parse(file)\n",
        "      parts = instrument.partitionByInstrument(midi)\n",
        "\n",
        "      if parts: # file has instrument parts\n",
        "          if len(parts.parts) > 1: # the file has more than one instrument\n",
        "            print(file, \"has more than one instrument\")\n",
        "            continue\n",
        "          else:\n",
        "            notes_to_parse = parts.parts[0].recurse()\n",
        "      else: # file has notes in a flat structure\n",
        "          notes_to_parse = midi.flat.notes\n",
        "      for element in notes_to_parse:\n",
        "          if isinstance(element, note.Note):\n",
        "              notes.append(str(element.pitch))\n",
        "          elif isinstance(element, chord.Chord):\n",
        "              notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "  \n",
        "    except:\n",
        "      print(file, \"could not be parsed\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.55% Complete\n",
            "1.09% Complete\n",
            "1.64% Complete\n",
            "2.19% Complete\n",
            "2.73% Complete\n",
            "3.28% Complete\n",
            "3.83% Complete\n",
            "4.37% Complete\n",
            "4.92% Complete\n",
            "5.46% Complete\n",
            "6.01% Complete\n",
            "6.56% Complete\n",
            "7.10% Complete\n",
            "7.65% Complete\n",
            "8.20% Complete\n",
            "8.74% Complete\n",
            "9.29% Complete\n",
            "9.84% Complete\n",
            "10.38% Complete\n",
            "10.93% Complete\n",
            "11.48% Complete\n",
            "12.02% Complete\n",
            "12.57% Complete\n",
            "13.11% Complete\n",
            "13.66% Complete\n",
            "14.21% Complete\n",
            "14.75% Complete\n",
            "15.30% Complete\n",
            "15.85% Complete\n",
            "16.39% Complete\n",
            "16.94% Complete\n",
            "17.49% Complete\n",
            "18.03% Complete\n",
            "18.58% Complete\n",
            "19.13% Complete\n",
            "19.67% Complete\n",
            "20.22% Complete\n",
            "20.77% Complete\n",
            "21.31% Complete\n",
            "21.86% Complete\n",
            "22.40% Complete\n",
            "22.95% Complete\n",
            "23.50% Complete\n",
            "24.04% Complete\n",
            "24.59% Complete\n",
            "25.14% Complete\n",
            "25.68% Complete\n",
            "26.23% Complete\n",
            "26.78% Complete\n",
            "27.32% Complete\n",
            "27.87% Complete\n",
            "28.42% Complete\n",
            "28.96% Complete\n",
            "29.51% Complete\n",
            "30.05% Complete\n",
            "30.60% Complete\n",
            "31.15% Complete\n",
            "31.69% Complete\n",
            "32.24% Complete\n",
            "32.79% Complete\n",
            "33.33% Complete\n",
            "33.88% Complete\n",
            "34.43% Complete\n",
            "34.97% Complete\n",
            "35.52% Complete\n",
            "36.07% Complete\n",
            "36.61% Complete\n",
            "37.16% Complete\n",
            "Chopin&Debussy/nocturnes_1_(c)siu.mid has more than one instrument\n",
            "37.70% Complete\n",
            "38.25% Complete\n",
            "Chopin&Debussy/nocturnes_2_(c)siu.mid has more than one instrument\n",
            "38.80% Complete\n",
            "39.34% Complete\n",
            "39.89% Complete\n",
            "40.44% Complete\n",
            "40.98% Complete\n",
            "41.53% Complete\n",
            "42.08% Complete\n",
            "42.62% Complete\n",
            "43.17% Complete\n",
            "43.72% Complete\n",
            "44.26% Complete\n",
            "44.81% Complete\n",
            "45.36% Complete\n",
            "45.90% Complete\n",
            "46.45% Complete\n",
            "46.99% Complete\n",
            "47.54% Complete\n",
            "48.09% Complete\n",
            "48.63% Complete\n",
            "49.18% Complete\n",
            "49.73% Complete\n",
            "50.27% Complete\n",
            "50.82% Complete\n",
            "51.37% Complete\n",
            "51.91% Complete\n",
            "52.46% Complete\n",
            "53.01% Complete\n",
            "53.55% Complete\n",
            "54.10% Complete\n",
            "54.64% Complete\n",
            "55.19% Complete\n",
            "55.74% Complete\n",
            "56.28% Complete\n",
            "56.83% Complete\n",
            "57.38% Complete\n",
            "57.92% Complete\n",
            "58.47% Complete\n",
            "59.02% Complete\n",
            "59.56% Complete\n",
            "60.11% Complete\n",
            "60.66% Complete\n",
            "61.20% Complete\n",
            "61.75% Complete\n",
            "62.30% Complete\n",
            "62.84% Complete\n",
            "63.39% Complete\n",
            "63.93% Complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAfSh4Bd4NLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# multiple files in parallel\n",
        "if not path.isdir(\"data\"):\n",
        "  os.mkdir(\"data\")\n",
        "\n",
        "filez = []\n",
        "for file in glob.glob(folder+\"/*.mid\"):\n",
        "    filez.append(file)\n",
        "\n",
        "def get_notes(file):\n",
        "\n",
        "  notes = []\n",
        "  notes_to_parse = None\n",
        "  midi = converter.parse(file)\n",
        "  parts = instrument.partitionByInstrument(midi)\n",
        "\n",
        "  try:\n",
        "    if parts: # file has instrument parts\n",
        "        if len(parts.parts) > 1: # the file has more than one instrument\n",
        "          print(file, \"has more than one instrument\")\n",
        "          return\n",
        "        else:\n",
        "          notes_to_parse = parts.parts[0].recurse()\n",
        "    else: # file has notes in a flat structure\n",
        "        notes_to_parse = midi.flat.notes\n",
        "    for element in notes_to_parse:\n",
        "        if isinstance(element, note.Note):\n",
        "            notes.append(str(element.pitch))\n",
        "        elif isinstance(element, chord.Chord):\n",
        "            notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "  except:\n",
        "    print(file, \"could not be parsed\")\n",
        "    \n",
        "  with open('data/notes', 'wb') as filepath:\n",
        "    pickle.dump(notes, filepath)\n",
        "\n",
        "  return notes\n",
        "\n",
        "output = common.runParallel(filez, parallelFunction=get_notes)\n",
        "\n",
        "notes = []\n",
        "with (open(\"data/notes\", \"rb\")) as openfile:\n",
        "    while True:\n",
        "        try:\n",
        "          notes.append(pickle.load(openfile))\n",
        "        except EOFError:\n",
        "          print(\"EOFError\")\n",
        "          break\n",
        "\n",
        "notes = []\n",
        "if os.path.getsize(\"data/notes\") > 0:      \n",
        "    with open(\"data/notes\", \"rb\") as f:\n",
        "        unpickler = pickle.Unpickler(f)\n",
        "        # if file is not empty scores will be equal\n",
        "        # to the value unpickled\n",
        "        notes = unpickler.load()\n",
        "\n",
        "del filez"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVPIBftK6dL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequence_length = 125 # CHANGE - EXPERIMENT\n",
        "\n",
        "# get all pitch names\n",
        "pitchnames = sorted(set(item for item in notes))\n",
        "\n",
        "# create a dictionary to map pitches to integers\n",
        "note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "network_input = []\n",
        "network_output = []\n",
        "\n",
        "# create input sequences and the corresponding outputs\n",
        "for i in range(0, len(notes) - sequence_length, 1):\n",
        "    sequence_in = notes[i:i + sequence_length]\n",
        "    sequence_out = notes[i + sequence_length]\n",
        "    network_input.append([note_to_int[char] for char in sequence_in])\n",
        "    network_output.append(note_to_int[sequence_out])\n",
        "    \n",
        "n_patterns = len(network_input)\n",
        "\n",
        "# reshape the input into a format compatible with LSTM layers\n",
        "network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "\n",
        "n_vocab = np.amax(network_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uur64Fup8Tr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalize input\n",
        "network_input = np.divide(network_input, float(n_vocab))\n",
        "network_output = np_utils.to_categorical(network_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-q47OdT-SmC",
        "colab_type": "code",
        "outputId": "7e372e47-94b1-4ffc-c876-c1783222d09e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(network_input.shape[1], network_input.shape[2]), return_sequences=True, kernel_initializer=initializers.RandomNormal(stddev=0.175),\n",
        "    bias_initializer=initializers.Zeros()))\n",
        "model.add(Dropout(0.225))\n",
        "model.add(LSTM(512, return_sequences=True, kernel_initializer=initializers.RandomNormal(stddev=0.175),\n",
        "    bias_initializer=initializers.Zeros()))\n",
        "model.add(Dropout(0.225))\n",
        "model.add(LSTM(256, kernel_initializer=initializers.RandomNormal(stddev=0.175),\n",
        "    bias_initializer=initializers.Zeros()))\n",
        "model.add(Dense(256, kernel_initializer=initializers.RandomNormal(stddev=0.175),\n",
        "    bias_initializer=initializers.Zeros()))\n",
        "model.add(Dropout(0.225))\n",
        "model.add(Dense(n_vocab+1, kernel_initializer=initializers.RandomNormal(stddev=0.25),\n",
        "    bias_initializer=initializers.Zeros()))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_4 (LSTM)                (None, 100, 256)          264192    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 100, 256)          0         \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 100, 512)          1574912   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 100, 512)          0         \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 256)               787456    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 285)               73245     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 285)               0         \n",
            "=================================================================\n",
            "Total params: 2,765,597\n",
            "Trainable params: 2,765,597\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-H8Y7RSLgYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_notes = len(notes)\n",
        "batch = 25\n",
        "step = int(np.ceil(num_notes / float(batch)))\n",
        "input_dim = int(network_input.shape[1])\n",
        "hidden = int(network_input.shape[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYZ0l2sAKx2b",
        "colab_type": "code",
        "outputId": "a095d1d2-a359-4e82-ca3f-de16689e2370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "# The LSTM  model -  output_shape = (batch, step, hidden)\n",
        "model1 = Sequential()\n",
        "model1.add(LSTM(input_dim=input_dim, output_dim=hidden, input_length=step, return_sequences=True))\n",
        "\n",
        "# The weight model  - actual output shape  = (batch, step)\n",
        "# after reshape : output_shape = (batch, step,  hidden)\n",
        "model2 = Sequential()\n",
        "model2.add(Dense(input_dim=input_dim, output_dim=step))\n",
        "model2.add(Activation('softmax')) # Learn a probability distribution over each  step.\n",
        "#Reshape to match LSTM's output shape, so that we can do element-wise multiplication.\n",
        "model2.add(RepeatVector(hidden))\n",
        "print(model2.output_shape)\n",
        "model2.add(Permute(2, 1), input_shape=(1280, 1))\n",
        "\n",
        "# The final model which gives the weighted sum:\n",
        "model = Sequential()\n",
        "merged = Concatenate()([model1, model2])\n",
        "model.add(merged)  # Multiply each element with corresponding weight a[i][j][k] * b[i][j]\n",
        "model.add(TimeDistributedMerge('sum')) # Sum the weighted elements.\n",
        "\n",
        "#model.compile(loss='mse', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 1, 1280)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(return_sequences=True, input_shape=(1280, 100..., units=1)`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=100, units=1280)`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-76582968e85f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRepeatVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1280\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# The final model which gives the weighted sum:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() takes 2 positional arguments but 3 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4liZVKDFxAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NYh2AdE_H0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# checkpointer\n",
        "checkpoint = ModelCheckpoint(\"MusicAI_best.hdf5\", \n",
        "                             monitor='loss', \n",
        "                             verbose=1,        \n",
        "                             save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt84eRBeSSuI",
        "colab_type": "code",
        "outputId": "98cd4ea0-cb46-4a3a-cdf4-db45444bf245",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train model\n",
        "model.fit(network_input, network_output, epochs=50, batch_size=batch, callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "31900/31900 [==============================] - 600s 19ms/step - loss: 4.5648 - acc: 0.0381\n",
            "\n",
            "Epoch 00001: loss improved from inf to 4.56478, saving model to MusicAI_best.hdf5\n",
            "Epoch 2/50\n",
            "31900/31900 [==============================] - 581s 18ms/step - loss: 4.3164 - acc: 0.0444\n",
            "\n",
            "Epoch 00002: loss improved from 4.56478 to 4.31637, saving model to MusicAI_best.hdf5\n",
            "Epoch 3/50\n",
            "31900/31900 [==============================] - 563s 18ms/step - loss: 4.2842 - acc: 0.0467\n",
            "\n",
            "Epoch 00003: loss improved from 4.31637 to 4.28423, saving model to MusicAI_best.hdf5\n",
            "Epoch 4/50\n",
            "31900/31900 [==============================] - 563s 18ms/step - loss: 4.2670 - acc: 0.0474\n",
            "\n",
            "Epoch 00004: loss improved from 4.28423 to 4.26698, saving model to MusicAI_best.hdf5\n",
            "Epoch 5/50\n",
            "31900/31900 [==============================] - 562s 18ms/step - loss: 4.2294 - acc: 0.0508\n",
            "\n",
            "Epoch 00005: loss improved from 4.26698 to 4.22944, saving model to MusicAI_best.hdf5\n",
            "Epoch 6/50\n",
            "31900/31900 [==============================] - 567s 18ms/step - loss: 4.2003 - acc: 0.0520\n",
            "\n",
            "Epoch 00006: loss improved from 4.22944 to 4.20032, saving model to MusicAI_best.hdf5\n",
            "Epoch 7/50\n",
            "31900/31900 [==============================] - 569s 18ms/step - loss: 4.1783 - acc: 0.0532\n",
            "\n",
            "Epoch 00007: loss improved from 4.20032 to 4.17829, saving model to MusicAI_best.hdf5\n",
            "Epoch 8/50\n",
            "31900/31900 [==============================] - 573s 18ms/step - loss: 4.1475 - acc: 0.0553\n",
            "\n",
            "Epoch 00008: loss improved from 4.17829 to 4.14753, saving model to MusicAI_best.hdf5\n",
            "Epoch 9/50\n",
            "31900/31900 [==============================] - 566s 18ms/step - loss: 4.0953 - acc: 0.0610\n",
            "\n",
            "Epoch 00009: loss improved from 4.14753 to 4.09531, saving model to MusicAI_best.hdf5\n",
            "Epoch 10/50\n",
            "31900/31900 [==============================] - 566s 18ms/step - loss: 4.0328 - acc: 0.0687\n",
            "\n",
            "Epoch 00010: loss improved from 4.09531 to 4.03278, saving model to MusicAI_best.hdf5\n",
            "Epoch 11/50\n",
            "31900/31900 [==============================] - 567s 18ms/step - loss: 3.9563 - acc: 0.0788\n",
            "\n",
            "Epoch 00011: loss improved from 4.03278 to 3.95630, saving model to MusicAI_best.hdf5\n",
            "Epoch 12/50\n",
            "31900/31900 [==============================] - 571s 18ms/step - loss: 3.8610 - acc: 0.0939\n",
            "\n",
            "Epoch 00012: loss improved from 3.95630 to 3.86096, saving model to MusicAI_best.hdf5\n",
            "Epoch 13/50\n",
            "31900/31900 [==============================] - 573s 18ms/step - loss: 3.7603 - acc: 0.1135\n",
            "\n",
            "Epoch 00013: loss improved from 3.86096 to 3.76025, saving model to MusicAI_best.hdf5\n",
            "Epoch 14/50\n",
            "31900/31900 [==============================] - 574s 18ms/step - loss: 3.6536 - acc: 0.1287\n",
            "\n",
            "Epoch 00014: loss improved from 3.76025 to 3.65359, saving model to MusicAI_best.hdf5\n",
            "Epoch 15/50\n",
            "31900/31900 [==============================] - 582s 18ms/step - loss: 3.5457 - acc: 0.1501\n",
            "\n",
            "Epoch 00015: loss improved from 3.65359 to 3.54565, saving model to MusicAI_best.hdf5\n",
            "Epoch 16/50\n",
            "31900/31900 [==============================] - 573s 18ms/step - loss: 3.4171 - acc: 0.1723\n",
            "\n",
            "Epoch 00016: loss improved from 3.54565 to 3.41712, saving model to MusicAI_best.hdf5\n",
            "Epoch 17/50\n",
            "31900/31900 [==============================] - 572s 18ms/step - loss: 3.2787 - acc: 0.1980\n",
            "\n",
            "Epoch 00017: loss improved from 3.41712 to 3.27873, saving model to MusicAI_best.hdf5\n",
            "Epoch 18/50\n",
            "31900/31900 [==============================] - 574s 18ms/step - loss: 3.1287 - acc: 0.2311\n",
            "\n",
            "Epoch 00018: loss improved from 3.27873 to 3.12874, saving model to MusicAI_best.hdf5\n",
            "Epoch 19/50\n",
            "31900/31900 [==============================] - 568s 18ms/step - loss: 2.9664 - acc: 0.2602\n",
            "\n",
            "Epoch 00019: loss improved from 3.12874 to 2.96637, saving model to MusicAI_best.hdf5\n",
            "Epoch 20/50\n",
            "31900/31900 [==============================] - 568s 18ms/step - loss: 2.8191 - acc: 0.2894\n",
            "\n",
            "Epoch 00020: loss improved from 2.96637 to 2.81915, saving model to MusicAI_best.hdf5\n",
            "Epoch 21/50\n",
            "31900/31900 [==============================] - 571s 18ms/step - loss: 2.6746 - acc: 0.3192\n",
            "\n",
            "Epoch 00021: loss improved from 2.81915 to 2.67459, saving model to MusicAI_best.hdf5\n",
            "Epoch 22/50\n",
            "31900/31900 [==============================] - 570s 18ms/step - loss: 2.5181 - acc: 0.3514\n",
            "\n",
            "Epoch 00022: loss improved from 2.67459 to 2.51815, saving model to MusicAI_best.hdf5\n",
            "Epoch 23/50\n",
            "31900/31900 [==============================] - 574s 18ms/step - loss: 2.3802 - acc: 0.3816\n",
            "\n",
            "Epoch 00023: loss improved from 2.51815 to 2.38024, saving model to MusicAI_best.hdf5\n",
            "Epoch 24/50\n",
            "31900/31900 [==============================] - 576s 18ms/step - loss: 2.2398 - acc: 0.4155\n",
            "\n",
            "Epoch 00024: loss improved from 2.38024 to 2.23975, saving model to MusicAI_best.hdf5\n",
            "Epoch 25/50\n",
            "31900/31900 [==============================] - 580s 18ms/step - loss: 2.1124 - acc: 0.4396\n",
            "\n",
            "Epoch 00025: loss improved from 2.23975 to 2.11238, saving model to MusicAI_best.hdf5\n",
            "Epoch 26/50\n",
            "31900/31900 [==============================] - 575s 18ms/step - loss: 1.9804 - acc: 0.4713\n",
            "\n",
            "Epoch 00026: loss improved from 2.11238 to 1.98042, saving model to MusicAI_best.hdf5\n",
            "Epoch 27/50\n",
            "31900/31900 [==============================] - 575s 18ms/step - loss: 1.8647 - acc: 0.4990\n",
            "\n",
            "Epoch 00027: loss improved from 1.98042 to 1.86465, saving model to MusicAI_best.hdf5\n",
            "Epoch 28/50\n",
            "31900/31900 [==============================] - 572s 18ms/step - loss: 1.7414 - acc: 0.5296\n",
            "\n",
            "Epoch 00028: loss improved from 1.86465 to 1.74139, saving model to MusicAI_best.hdf5\n",
            "Epoch 29/50\n",
            "31900/31900 [==============================] - 571s 18ms/step - loss: 1.6266 - acc: 0.5508\n",
            "\n",
            "Epoch 00029: loss improved from 1.74139 to 1.62658, saving model to MusicAI_best.hdf5\n",
            "Epoch 30/50\n",
            "31900/31900 [==============================] - 568s 18ms/step - loss: 1.5101 - acc: 0.5821\n",
            "\n",
            "Epoch 00030: loss improved from 1.62658 to 1.51014, saving model to MusicAI_best.hdf5\n",
            "Epoch 31/50\n",
            "31900/31900 [==============================] - 571s 18ms/step - loss: 1.4144 - acc: 0.6067\n",
            "\n",
            "Epoch 00031: loss improved from 1.51014 to 1.41440, saving model to MusicAI_best.hdf5\n",
            "Epoch 32/50\n",
            "31900/31900 [==============================] - 574s 18ms/step - loss: 1.3238 - acc: 0.6267\n",
            "\n",
            "Epoch 00032: loss improved from 1.41440 to 1.32382, saving model to MusicAI_best.hdf5\n",
            "Epoch 33/50\n",
            "31900/31900 [==============================] - 569s 18ms/step - loss: 1.2251 - acc: 0.6539\n",
            "\n",
            "Epoch 00033: loss improved from 1.32382 to 1.22506, saving model to MusicAI_best.hdf5\n",
            "Epoch 34/50\n",
            "31900/31900 [==============================] - 571s 18ms/step - loss: 1.1508 - acc: 0.6690\n",
            "\n",
            "Epoch 00034: loss improved from 1.22506 to 1.15076, saving model to MusicAI_best.hdf5\n",
            "Epoch 35/50\n",
            "31900/31900 [==============================] - 567s 18ms/step - loss: 1.0681 - acc: 0.6895\n",
            "\n",
            "Epoch 00035: loss improved from 1.15076 to 1.06814, saving model to MusicAI_best.hdf5\n",
            "Epoch 36/50\n",
            "31900/31900 [==============================] - 572s 18ms/step - loss: 0.9770 - acc: 0.7155\n",
            "\n",
            "Epoch 00036: loss improved from 1.06814 to 0.97702, saving model to MusicAI_best.hdf5\n",
            "Epoch 37/50\n",
            "31900/31900 [==============================] - 568s 18ms/step - loss: 0.9275 - acc: 0.7285\n",
            "\n",
            "Epoch 00037: loss improved from 0.97702 to 0.92747, saving model to MusicAI_best.hdf5\n",
            "Epoch 38/50\n",
            "31900/31900 [==============================] - 569s 18ms/step - loss: 0.8549 - acc: 0.7487\n",
            "\n",
            "Epoch 00038: loss improved from 0.92747 to 0.85493, saving model to MusicAI_best.hdf5\n",
            "Epoch 39/50\n",
            "31900/31900 [==============================] - 574s 18ms/step - loss: 0.8106 - acc: 0.7603\n",
            "\n",
            "Epoch 00039: loss improved from 0.85493 to 0.81056, saving model to MusicAI_best.hdf5\n",
            "Epoch 40/50\n",
            "31900/31900 [==============================] - 571s 18ms/step - loss: 0.7438 - acc: 0.7784\n",
            "\n",
            "Epoch 00040: loss improved from 0.81056 to 0.74375, saving model to MusicAI_best.hdf5\n",
            "Epoch 41/50\n",
            "31900/31900 [==============================] - 571s 18ms/step - loss: 0.7003 - acc: 0.7918\n",
            "\n",
            "Epoch 00041: loss improved from 0.74375 to 0.70034, saving model to MusicAI_best.hdf5\n",
            "Epoch 42/50\n",
            "31900/31900 [==============================] - 571s 18ms/step - loss: 0.6417 - acc: 0.8052\n",
            "\n",
            "Epoch 00042: loss improved from 0.70034 to 0.64171, saving model to MusicAI_best.hdf5\n",
            "Epoch 43/50\n",
            "31900/31900 [==============================] - 571s 18ms/step - loss: 0.6135 - acc: 0.8152\n",
            "\n",
            "Epoch 00043: loss improved from 0.64171 to 0.61345, saving model to MusicAI_best.hdf5\n",
            "Epoch 44/50\n",
            "31900/31900 [==============================] - 569s 18ms/step - loss: 0.5780 - acc: 0.8253\n",
            "\n",
            "Epoch 00044: loss improved from 0.61345 to 0.57800, saving model to MusicAI_best.hdf5\n",
            "Epoch 45/50\n",
            "31900/31900 [==============================] - 573s 18ms/step - loss: 0.5629 - acc: 0.8294\n",
            "\n",
            "Epoch 00045: loss improved from 0.57800 to 0.56290, saving model to MusicAI_best.hdf5\n",
            "Epoch 46/50\n",
            "31900/31900 [==============================] - 572s 18ms/step - loss: 0.5174 - acc: 0.8418\n",
            "\n",
            "Epoch 00046: loss improved from 0.56290 to 0.51741, saving model to MusicAI_best.hdf5\n",
            "Epoch 47/50\n",
            "31900/31900 [==============================] - 575s 18ms/step - loss: 0.4872 - acc: 0.8519\n",
            "\n",
            "Epoch 00047: loss improved from 0.51741 to 0.48715, saving model to MusicAI_best.hdf5\n",
            "Epoch 48/50\n",
            "31900/31900 [==============================] - 569s 18ms/step - loss: 0.4722 - acc: 0.8581\n",
            "\n",
            "Epoch 00048: loss improved from 0.48715 to 0.47222, saving model to MusicAI_best.hdf5\n",
            "Epoch 49/50\n",
            "31900/31900 [==============================] - 569s 18ms/step - loss: 0.4459 - acc: 0.8632\n",
            "\n",
            "Epoch 00049: loss improved from 0.47222 to 0.44585, saving model to MusicAI_best.hdf5\n",
            "Epoch 50/50\n",
            "31900/31900 [==============================] - 568s 18ms/step - loss: 0.4315 - acc: 0.8692\n",
            "\n",
            "Epoch 00050: loss improved from 0.44585 to 0.43148, saving model to MusicAI_best.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f2dddf13e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bisZ1kjn_1TH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make piece\n",
        "start = np.random.randint(0, len(network_input)-1)\n",
        "int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
        "pattern = network_input[start]\n",
        "prediction_output = []\n",
        "\n",
        "# generate 10000 notes\n",
        "for note_index in range(10000):\n",
        "    prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
        "    prediction_input = prediction_input / float(n_vocab)\n",
        "    prediction = model.predict(prediction_input, verbose=0)\n",
        "    index = np.argmax(prediction)\n",
        "    result = int_to_note[index]\n",
        "    prediction_output.append(result)\n",
        "    pattern = np.append(pattern, index)\n",
        "    pattern = pattern[1:len(pattern)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z20Ms2ruA58T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make piece\n",
        "offset = 0\n",
        "output_notes = []\n",
        "# create note and chord objects based on the values generated by the model\n",
        "for pattern in prediction_output:\n",
        "    # pattern is a chord\n",
        "    if ('.' in pattern) or pattern.isdigit():\n",
        "        notes_in_chord = pattern.split('.')\n",
        "        notes = []\n",
        "        for current_note in notes_in_chord:\n",
        "            new_note = note.Note(int(current_note))\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            notes.append(new_note)\n",
        "        new_chord = chord.Chord(notes)\n",
        "        new_chord.offset = offset\n",
        "        output_notes.append(new_chord)\n",
        "    # pattern is a note\n",
        "    else:\n",
        "        new_note = note.Note(pattern)\n",
        "        new_note.offset = offset\n",
        "        new_note.storedInstrument = instrument.Piano()\n",
        "        output_notes.append(new_note)\n",
        "    # increase offset each iteration so that notes do not stack\n",
        "    offset += 0.5 # offset += 0.25"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LXfXEZUBB40",
        "colab_type": "code",
        "outputId": "90812fc3-be00-4720-af12-b7ccb0205516",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# stream piece into midi file\n",
        "midi_stream = stream.Stream(output_notes)\n",
        "midi_stream.write('midi', fp='output.mid')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'output.mid'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XG8TvT9QFbLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download piece\n",
        "files.download('/content/output.mid')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE0YzK8CI615",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}